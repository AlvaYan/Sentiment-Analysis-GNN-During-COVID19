{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This script preprocess comment graph.\n",
    "#Output graphs should include input feature, label, train index, test index, adjacency matrix\n",
    "#this script contain preprocessings for labels and index files. For other data preprocessing, \n",
    "#you can either modify it from step 0, or contact author for code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this before running any subsequent block below\n",
    "#counting roughly how many pos/neg/neu are out there for combined Dartmouth set\n",
    "#Use this proportion to determine how much neutral class in \"non-neg\" class for testing dataset\n",
    "import numpy as np \n",
    "import urllib.request \n",
    "import os \n",
    "import csv \n",
    "import requests \n",
    "import time\n",
    "import math\n",
    "import rando\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import re, string, unicodedata\n",
    "import nltk\n",
    "import contractions\n",
    "import inflect\n",
    "import heapq\n",
    "import pickle\n",
    "import warnings\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "filepath2=\"C:\\\\Backup of covid project\\\\2cls_posVSnonpos\\\\data\\\\\"\n",
    "path=\"C:\\\\Backup of covid project\\\\2cls_posVSnonpos\\\\data\\\\\"\n",
    "\n",
    "types=[\"comment\"]\n",
    "years=['2019','2020']\n",
    "#years=['2020']\n",
    "schools = [\"notredame\",\"uofm\",\"columbia\",\"UCSD\",\"berkeley\",\"Harvard\",\"ucla\"]\n",
    "ct_thr=150\n",
    "\n",
    "#Positive: 1, negative:0\n",
    "#2020:1, 2019:0\n",
    "label_group=[\"label\",\"unlabel\"]\n",
    "months=['08','09','10','11']\n",
    "\n",
    "att_com=['time','id','body','Emotion','emo_pred']\n",
    "drop_com=[\"link_id\",'Topic',\"parent_id\",\"author_fullname\",\"author\",\"gildings\",\"score\",\"subreddit\",\"no_follow\",\"total_awards_received\",\"all_awardings\",\"is_submitter\",\"locked\",\"send_replies\",\"stickied\",]\n",
    "emo=[\"Very Positive\",\"Positive\",\"Neutral\",\"Negative\",\"Very negative\"]\n",
    "top=[\"Covid\",\"Academics\",\"Sports\",\"Campus/Students Life\",\"Social Media\",\"Religion\",\"Politics\",\"Others\"]\n",
    "\n",
    "#Positive: 1, negative:0\n",
    "num=[]\n",
    "for t in types:\n",
    "    for s in schools:\n",
    "        num_sch=[]\n",
    "        for y in years:\n",
    "            pos=0\n",
    "            neu=0\n",
    "            neg=0\n",
    "            for l in label_group:\n",
    "                f=s+t+y+l+\".csv\"\n",
    "                os.chdir(filepath2)\n",
    "                data=pd.read_csv(f,skip_blank_lines=True)\n",
    "                data=data[['body','Emotion']]\n",
    "                ct=0\n",
    "                for e in data['Emotion'].values:\n",
    "                    row=[0,0]\n",
    "                    if e=='Negative' or e=='Very negative':\n",
    "                        neg+=1\n",
    "                    elif e=='Positive' or e=='Very Positive':\n",
    "                        pos+=1\n",
    "                    elif e=='Neutral':\n",
    "                        neu+=1\n",
    "                    ct+=1\n",
    "                    if ct>ct_thr:\n",
    "                        break\n",
    "            num_sch.append([neg,neu,pos])\n",
    "        num.append(num_sch)\n",
    "                \n",
    "                \n",
    "s='dartmouth'\n",
    "f1='dartmouthcomment2019label.csv'\n",
    "f2='dartmouthcomment2019unlabel.csv'\n",
    "f3='dartmouthcomment2020label.csv'\n",
    "f4='dartmouthcomment2020unlabel.csv'\n",
    "os.chdir(filepath2)\n",
    "data1=pd.read_csv(f1,skip_blank_lines=True)\n",
    "data1=data1.drop(drop_com, axis=1)\n",
    "data2=pd.read_csv(f2,skip_blank_lines=True)\n",
    "data2=data2.drop(drop_com, axis=1)\n",
    "data3=pd.read_csv(f3,skip_blank_lines=True)\n",
    "data3=data3.drop(drop_com, axis=1)\n",
    "data4=pd.read_csv(f4,skip_blank_lines=True)\n",
    "data4=data4.drop(drop_com, axis=1)\n",
    "data = pd.concat([data1,data2,data3,data4], axis=0).reset_index(drop=True)\n",
    "data=data[['body','Emotion']]\n",
    "pos=0\n",
    "neu=0\n",
    "neg=0\n",
    "ct=0\n",
    "for e in data['Emotion'].values:\n",
    "    if e=='Negative' or e=='Very negative':\n",
    "        neg+=1\n",
    "    elif e=='Positive' or e=='Very Positive':\n",
    "        pos+=1\n",
    "    elif e=='Neutral':\n",
    "        neu+=1\n",
    "    ct+=1\n",
    "    if ct>ct_thr:\n",
    "        break\n",
    "num_sch=[]\n",
    "num_sch.append([0,0,0])\n",
    "num_sch.append([neg,neu,pos])\n",
    "num.append(num_sch)\n",
    "\n",
    "prop=sum(sum(np.array(num)))\n",
    "neu2neg_neu=prop[1]/(prop[0]+prop[1])\n",
    "neu2pos_neu=prop[1]/(prop[2]+prop[1])\n",
    "print(prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formualte train/test set by formulating sets of indices\n",
    "#For neg VS non-neg\n",
    "import numpy as np \n",
    "import urllib.request \n",
    "import os \n",
    "import csv \n",
    "import requests \n",
    "import time\n",
    "import math\n",
    "import rando\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import re, string, unicodedata\n",
    "import nltk\n",
    "import contractions\n",
    "import inflect\n",
    "\n",
    "import math\n",
    "#stopword = stopwords.words(‘english’)\n",
    "import warnings\n",
    "import random\n",
    "import scipy.sparse\n",
    "\n",
    "path_result='C:\\\\Backup of covid project\\\\2cls_negVSnonneg\\\\results\\\\'\n",
    "path_data=\"C:\\\\Backup of covid project\\\\2cls_negVSnonneg\\\\data\\\\\"\n",
    "path_code=\"C:\\\\Backup of covid project\\\\\"\n",
    "\n",
    "random.seed(10)\n",
    "filepath=path_data\n",
    "path=path_data\n",
    "os.chdir(filepath)\n",
    "\n",
    "types=[\"comment\"]\n",
    "years=['2019','2020']\n",
    "\n",
    "label_group=[\"label\",\"unlabel\"]\n",
    "months=['08','09','10','11']\n",
    "\n",
    "drop_com=[\"link_id\",\"parent_id\",\"author_fullname\",\"author\",\"gildings\",\"score\",\"subreddit\",\"no_follow\",\"total_awards_received\",\"all_awardings\",\"is_submitter\",\"locked\",\"send_replies\",\"stickied\",]\n",
    "att_com=[\"time\",\"id\",\"body\",\"Emotion\",\"Topic\"]\n",
    "emo=[\"Very negative\",\"Negative\",\"Neutral\",\"Positive\",\"Very Positive\"]\n",
    "top=[\"Covid\",\"Academics\",\"Sports\",\"Campus/Students Life\",\"Social Media\",\"Religion\",\"Politics\",\"Others\"]\n",
    "\n",
    "#FIRST DEAL WITH DARTMOUTH DATA\n",
    "#schools = [\"notredame\",\"uofm\",\"columbia\",\"dartmouth\",\"UCSD\",\"berkeley\",\"Harvard\",\"ucla\"]\n",
    "schools = [\"dartmouth\"]\n",
    "for t in types:\n",
    "    for s in schools:\n",
    "        train_index=[]\n",
    "        test_index=[]\n",
    "        to_be_labeled_index=[]\n",
    "        idx=0\n",
    "        \n",
    "        n_neu=np.round(50*neu2pos_neu)\n",
    "        n_test=[50,n_neu,50-n_neu]\n",
    "        for y in years:\n",
    "            for l in label_group:\n",
    "                f=s+t+y+l+\".csv\"\n",
    "                os.chdir(filepath)\n",
    "                data=pd.read_csv(f,skip_blank_lines=True)\n",
    "                data=data.drop(drop_com, axis=1)\n",
    "                for d in range(len(data['id'])):\n",
    "                    if str(data['time'][d])[4:6] in months:\n",
    "                        if isinstance(data['Emotion'][d],str)==False:\n",
    "                            to_be_labeled_index.append(idx)\n",
    "                        elif data['Emotion'][d]==emo[0] and n_test[0]>0:\n",
    "                            test_index.append(idx)\n",
    "                            n_test[0]=n_test[0]-1\n",
    "                        elif data['Emotion'][d]==emo[0]:\n",
    "                            train_index.append(idx)\n",
    "                        elif data['Emotion'][d]==emo[1] and n_test[0]>0:\n",
    "                            test_index.append(idx)\n",
    "                            n_test[0]=n_test[0]-1\n",
    "                        elif data['Emotion'][d]==emo[1]:\n",
    "                            train_index.append(idx)\n",
    "                        elif data['Emotion'][d]==emo[2] and n_test[1]>0:\n",
    "                            test_index.append(idx)\n",
    "                            n_test[1]=n_test[1]-1\n",
    "                        elif data['Emotion'][d]==emo[2]:\n",
    "                            train_index.append(idx)\n",
    "                        elif data['Emotion'][d]==emo[3] and n_test[2]>0:\n",
    "                            test_index.append(idx)\n",
    "                            n_test[2]=n_test[2]-1\n",
    "                        elif data['Emotion'][d]==emo[3]:\n",
    "                            train_index.append(idx)\n",
    "                        elif data['Emotion'][d]==emo[4] and n_test[2]>0:\n",
    "                            test_index.append(idx)\n",
    "                            n_test[2]=n_test[2]-1\n",
    "                        elif data['Emotion'][d]==emo[4]:\n",
    "                            train_index.append(idx)\n",
    "                        else:\n",
    "                            to_be_labeled_index.append(idx)\n",
    "            \n",
    "                        os.chdir(path)  \n",
    "                        \n",
    "            \n",
    "                        idx=idx+1\n",
    "                        if idx/600-int(idx/600)==0:\n",
    "                            print(s+str(idx))    \n",
    "        os.chdir(path)\n",
    "        name=\"train_index_\"+s+\"_cm.p\"\n",
    "        pickle.dump(train_index,open(name,\"wb\"))\n",
    "        name=\"test_index_\"+s+\"_cm.p\"\n",
    "        pickle.dump(test_index,open(name,\"wb\"))\n",
    "        name=\"to_be_labeled_index_\"+s+\"_cm.p\"\n",
    "        pickle.dump(to_be_labeled_index,open(name,\"wb\"))\n",
    "        \n",
    "#deal with other schools\n",
    "schools = [\"notredame\",\"uofm\",\"columbia\",\"UCSD\",\"berkeley\",\"Harvard\",\"ucla\"]\n",
    "for t in types:\n",
    "    for s in schools:\n",
    "        for y in years:\n",
    "            train_index=[]\n",
    "            test_index=[]\n",
    "            to_be_labeled_index=[]\n",
    "            idx=0\n",
    "            n_neu=np.round(50*neu2pos_neu)\n",
    "            n_test=[50,n_neu,50-n_neu]\n",
    "            for l in label_group:\n",
    "                f=s+t+y+l+\".csv\"\n",
    "                os.chdir(filepath)\n",
    "                data=pd.read_csv(f,skip_blank_lines=True)\n",
    "                data=data.drop(drop_com, axis=1)\n",
    "                for d in range(len(data['id'])):\n",
    "                    if str(data['time'][d])[4:6] in months:\n",
    "                        if isinstance(data['Emotion'][d],str)==False:\n",
    "                            to_be_labeled_index.append(idx)\n",
    "                        elif data['Emotion'][d]==emo[0] and n_test[0]>0:\n",
    "                            test_index.append(idx)\n",
    "                            n_test[0]=n_test[0]-1\n",
    "                        elif data['Emotion'][d]==emo[0]:\n",
    "                            train_index.append(idx)\n",
    "                        elif data['Emotion'][d]==emo[1] and n_test[0]>0:\n",
    "                            test_index.append(idx)\n",
    "                            n_test[0]=n_test[0]-1\n",
    "                        elif data['Emotion'][d]==emo[1]:\n",
    "                            train_index.append(idx)\n",
    "                        elif data['Emotion'][d]==emo[2] and n_test[1]>0:\n",
    "                            test_index.append(idx)\n",
    "                            n_test[1]=n_test[1]-1\n",
    "                        elif data['Emotion'][d]==emo[2]:\n",
    "                            to_be_labeled_index.append(idx)\n",
    "                        elif data['Emotion'][d]==emo[3] and n_test[2]>0:\n",
    "                            test_index.append(idx)\n",
    "                            n_test[2]=n_test[2]-1\n",
    "                        elif data['Emotion'][d]==emo[3]:\n",
    "                            train_index.append(idx)\n",
    "                        elif data['Emotion'][d]==emo[4] and n_test[2]>0:\n",
    "                            test_index.append(idx)\n",
    "                            n_test[2]=n_test[2]-1\n",
    "                        elif data['Emotion'][d]==emo[4]:\n",
    "                            train_index.append(idx)\n",
    "                        else:\n",
    "                            to_be_labeled_index.append(idx)\n",
    "            \n",
    "                        os.chdir(path)  \n",
    "                        \n",
    "            \n",
    "                        idx=idx+1\n",
    "                        if idx/600-int(idx/600)==0:\n",
    "                            print(s+str(idx))    \n",
    "            os.chdir(path)\n",
    "            name=\"train_index_\"+s+y+\"_cm.p\"\n",
    "            pickle.dump(train_index,open(name,\"wb\"))\n",
    "            name=\"test_index_\"+s+y+\"_cm.p\"\n",
    "            pickle.dump(test_index,open(name,\"wb\"))\n",
    "            name=\"to_be_labeled_index_\"+s+y+\"_cm.p\"\n",
    "            pickle.dump(to_be_labeled_index,open(name,\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting how much training sample we have for DM set \n",
    "#and count ho much testing sample we have for each dataset\n",
    "#for neg VS non-neg\n",
    "import numpy as np \n",
    "import urllib.request \n",
    "import os \n",
    "import csv \n",
    "import requests \n",
    "import time\n",
    "import math\n",
    "import rando\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import re, string, unicodedata\n",
    "import nltk\n",
    "import contractions\n",
    "import inflect\n",
    "import math\n",
    "#stopword = stopwords.words(‘english’)\n",
    "import warnings\n",
    "import random\n",
    "import scipy.sparse\n",
    "\n",
    "path_result='C:\\\\Backup of covid project\\\\2cls_negVSnonneg\\\\results\\\\'\n",
    "path_data=\"C:\\\\Backup of covid project\\\\2cls_negVSnonneg\\\\data\\\\\"\n",
    "path_code=\"C:\\\\Backup of covid project\\\\\"\n",
    "\n",
    "random.seed(10)\n",
    "filepath=path_data\n",
    "path=path_data\n",
    "os.chdir(filepath)\n",
    "\n",
    "types=[\"comment\"]\n",
    "years=['2019','2020']\n",
    "\n",
    "label_group=[\"label\",\"unlabel\"]\n",
    "months=['08','09','10','11']\n",
    "\n",
    "drop_com=[\"link_id\",\"parent_id\",\"author_fullname\",\"author\",\"gildings\",\"score\",\"subreddit\",\"no_follow\",\"total_awards_received\",\"all_awardings\",\"is_submitter\",\"locked\",\"send_replies\",\"stickied\",]\n",
    "att_com=[\"time\",\"id\",\"body\",\"Emotion\",\"Topic\"]\n",
    "\n",
    "#emo=[\"Very Positive\",\"Positive\",\"Neutral\",\"Negative\",\"Very negative\"]\n",
    "emo=[\"Very negative\",\"Negative\",\"Neutral\",\"Positive\",\"Very Positive\"]\n",
    "top=[\"Covid\",\"Academics\",\"Sports\",\"Campus/Students Life\",\"Social Media\",\"Religion\",\"Politics\",\"Others\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#FIRST DEAL WITH DARTMOUTH DATA\n",
    "schools = [\"dartmouth\"]\n",
    "for t in types:\n",
    "    for s in schools:\n",
    "        train_index=[]\n",
    "        test_index=[]\n",
    "        to_be_labeled_index=[]\n",
    "        idx=0\n",
    "        n_neu=np.round(50*neu2pos_neu)\n",
    "        n_test=[50,n_neu,50-n_neu]\n",
    "        train_neg=0\n",
    "        train_pos=0\n",
    "        train_neu=0\n",
    "        test_neg=0\n",
    "        test_pos=0\n",
    "        test_neu=0\n",
    "        for y in years:\n",
    "            for l in label_group:\n",
    "                f=s+t+y+l+\".csv\"\n",
    "                os.chdir(filepath)\n",
    "                data=pd.read_csv(f,skip_blank_lines=True)\n",
    "                data=data.drop(drop_com, axis=1)\n",
    "                for d in range(len(data['id'])):\n",
    "                    if str(data['time'][d])[4:6] in months:\n",
    "                        if isinstance(data['Emotion'][d],str)==False:\n",
    "                            to_be_labeled_index.append(idx)\n",
    "                        elif data['Emotion'][d]==emo[0] and n_test[0]>0:\n",
    "                            test_index.append(idx)\n",
    "                            n_test[0]=n_test[0]-1\n",
    "                            test_neg+=1\n",
    "                        elif data['Emotion'][d]==emo[0]:\n",
    "                            train_index.append(idx)\n",
    "                            train_neg+=1\n",
    "                        elif data['Emotion'][d]==emo[1] and n_test[0]>0:\n",
    "                            test_index.append(idx)\n",
    "                            n_test[0]=n_test[0]-1\n",
    "                            test_neg+=1\n",
    "                        elif data['Emotion'][d]==emo[1]:\n",
    "                            train_index.append(idx)\n",
    "                            train_neg+=1\n",
    "                        elif data['Emotion'][d]==emo[2] and n_test[1]>0:\n",
    "                            test_index.append(idx)\n",
    "                            n_test[1]=n_test[1]-1\n",
    "                            test_neu+=1\n",
    "                        elif data['Emotion'][d]==emo[2]:\n",
    "                            train_index.append(idx)\n",
    "                            train_neu+=1\n",
    "                        elif data['Emotion'][d]==emo[3] and n_test[2]>0:\n",
    "                            test_index.append(idx)\n",
    "                            n_test[2]=n_test[2]-1\n",
    "                            test_pos+=1\n",
    "                        elif data['Emotion'][d]==emo[3]:\n",
    "                            train_index.append(idx)\n",
    "                            train_pos+=1\n",
    "                        elif data['Emotion'][d]==emo[4] and n_test[2]>0:\n",
    "                            test_index.append(idx)\n",
    "                            n_test[2]=n_test[2]-1\n",
    "                            test_pos+=1\n",
    "                        elif data['Emotion'][d]==emo[4]:\n",
    "                            train_index.append(idx)\n",
    "                            train_pos+=1\n",
    "                        else:\n",
    "                            to_be_labeled_index.append(idx)\n",
    "            \n",
    "                        os.chdir(path)  \n",
    "                        \n",
    "            \n",
    "                        idx=idx+1 \n",
    "        print('training numbers in DM: '+str([train_neg,train_neu,train_pos]))\n",
    "        print('testing numbers in DM: '+str([test_neg,test_neu,test_pos]))\n",
    "        \n",
    "#Deal with other schools\n",
    "schools = [\"notredame\",\"uofm\",\"columbia\",\"UCSD\",\"berkeley\",\"Harvard\",\"ucla\"]\n",
    "for t in types:\n",
    "    for s in schools:\n",
    "        for y in years:\n",
    "            train_index=[]\n",
    "            test_index=[]\n",
    "            to_be_labeled_index=[]\n",
    "            idx=0\n",
    "            n_neu=np.round(50*neu2pos_neu)\n",
    "            n_test=[50,n_neu,50-n_neu]\n",
    "            test_neg=0\n",
    "            test_pos=0\n",
    "            test_neu=0\n",
    "            for l in label_group:\n",
    "                f=s+t+y+l+\".csv\"\n",
    "                os.chdir(filepath)\n",
    "                data=pd.read_csv(f,skip_blank_lines=True)\n",
    "                data=data.drop(drop_com, axis=1)\n",
    "                for d in range(len(data['id'])):\n",
    "                    if str(data['time'][d])[4:6] in months:\n",
    "                        if isinstance(data['Emotion'][d],str)==False:\n",
    "                            to_be_labeled_index.append(idx)\n",
    "                        elif data['Emotion'][d]==emo[0] and n_test[0]>0:\n",
    "                            test_index.append(idx)\n",
    "                            n_test[0]=n_test[0]-1\n",
    "                            test_neg+=1\n",
    "                        elif data['Emotion'][d]==emo[0]:\n",
    "                            to_be_labeled_index.append(idx)\n",
    "                        elif data['Emotion'][d]==emo[1] and n_test[0]>0:\n",
    "                            test_index.append(idx)\n",
    "                            n_test[0]=n_test[0]-1\n",
    "                            test_neg+=1\n",
    "                        elif data['Emotion'][d]==emo[1]:\n",
    "                            to_be_labeled_index.append(idx)\n",
    "                        elif data['Emotion'][d]==emo[2] and n_test[1]>0:\n",
    "                            test_index.append(idx)\n",
    "                            n_test[1]=n_test[1]-1\n",
    "                            test_neu+=1\n",
    "                        elif data['Emotion'][d]==emo[2]:\n",
    "                            to_be_labeled_index.append(idx)\n",
    "                        elif data['Emotion'][d]==emo[3] and n_test[2]>0:\n",
    "                            test_index.append(idx)\n",
    "                            n_test[2]=n_test[2]-1\n",
    "                            test_pos+=1\n",
    "                        elif data['Emotion'][d]==emo[3]:\n",
    "                            to_be_labeled_index.append(idx)\n",
    "                        elif data['Emotion'][d]==emo[4] and n_test[2]>0:\n",
    "                            test_index.append(idx)\n",
    "                            n_test[2]=n_test[2]-1\n",
    "                            test_pos+=1\n",
    "                        elif data['Emotion'][d]==emo[4]:\n",
    "                            to_be_labeled_index.append(idx)\n",
    "                        else:\n",
    "                            to_be_labeled_index.append(idx)\n",
    "            \n",
    "                        os.chdir(path)  \n",
    "                        \n",
    "            \n",
    "                        idx=idx+1\n",
    "                        #if idx/600-int(idx/600)==0:\n",
    "                        #    print(s+str(idx))    \n",
    "            print('testing numbers in '+s+y+\": \"+str([test_neg,test_neu,test_pos]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-adoption",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save each sample's class using one hot encoding\n",
    "#For neg VS non-neg\n",
    "import numpy as np \n",
    "import urllib.request \n",
    "import os \n",
    "import csv \n",
    "import requests \n",
    "import time\n",
    "import math\n",
    "import rando\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import re, string, unicodedata\n",
    "import nltk\n",
    "import contractions\n",
    "import inflect\n",
    "import heapq\n",
    "import pickle\n",
    "import warnings\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "#import tensorflow_hub as hub\n",
    "#import tensorflow_text\n",
    "\n",
    "filepath2=\"C:\\\\Backup of covid project\\\\2cls_negVSnonneg\\\\data\\\\\"\n",
    "\n",
    "path=\"C:\\\\Backup of covid project\\\\2cls_negVSnonneg\\\\data\\\\\"\n",
    "\n",
    "types=[\"comment\"]\n",
    "years=['2019','2020']\n",
    "#years=['2020']\n",
    "schools = [\"notredame\",\"uofm\",\"columbia\",\"UCSD\",\"berkeley\",\"Harvard\",\"ucla\"]\n",
    "\n",
    "#2020:1, 2019:0\n",
    "label_group=[\"label\",\"unlabel\"]\n",
    "months=['08','09','10','11']\n",
    "\n",
    "att_com=['time','id','body','Emotion','emo_pred']\n",
    "drop_com=[\"link_id\",'Topic',\"parent_id\",\"author_fullname\",\"author\",\"gildings\",\"score\",\"subreddit\",\"no_follow\",\"total_awards_received\",\"all_awardings\",\"is_submitter\",\"locked\",\"send_replies\",\"stickied\",]\n",
    "emo=[\"Very Positive\",\"Positive\",\"Neutral\",\"Negative\",\"Very negative\"]\n",
    "top=[\"Covid\",\"Academics\",\"Sports\",\"Campus/Students Life\",\"Social Media\",\"Religion\",\"Politics\",\"Others\"]\n",
    "\n",
    "#non-Neg: 1, negative:0\n",
    "for t in types:\n",
    "    for s in schools:\n",
    "        for y in years:\n",
    "            for l in label_group:\n",
    "                f=s+t+y+l+\".csv\"\n",
    "                os.chdir(filepath2)\n",
    "                data=pd.read_csv(f,skip_blank_lines=True)\n",
    "                data=data[['body','Emotion']]\n",
    "\n",
    "                for e in data['Emotion'].values:\n",
    "                    row=[0,0]\n",
    "                    if e=='Negative' or e=='Very negative':\n",
    "                        row=[1,0]\n",
    "                    elif e=='Positive' or e=='Very Positive':\n",
    "                        row=[0,1]\n",
    "                    elif e=='Neutral':\n",
    "                        row=[0,1]\n",
    "                \n",
    "                    #turning testing_index to testing_index_2cls\n",
    "                    os.chdir(path)  \n",
    "                        \n",
    "                    name=\"label_emt3_\"+s+y+\"_cm.csv\"\n",
    "                    e=open(name, 'a',newline='')\n",
    "                    with e:\n",
    "                        writer = csv.writer(e, delimiter=',')\n",
    "                        writer.writerow(row)\n",
    "                \n",
    "s='dartmouth'\n",
    "f1='dartmouthcomment2019label.csv'\n",
    "f2='dartmouthcomment2019unlabel.csv'\n",
    "f3='dartmouthcomment2020label.csv'\n",
    "f4='dartmouthcomment2020unlabel.csv'\n",
    "os.chdir(filepath2)\n",
    "data1=pd.read_csv(f1,skip_blank_lines=True)\n",
    "data1=data1.drop(drop_com, axis=1)\n",
    "data2=pd.read_csv(f2,skip_blank_lines=True)\n",
    "data2=data2.drop(drop_com, axis=1)\n",
    "data3=pd.read_csv(f3,skip_blank_lines=True)\n",
    "data3=data3.drop(drop_com, axis=1)\n",
    "data4=pd.read_csv(f4,skip_blank_lines=True)\n",
    "data4=data4.drop(drop_com, axis=1)\n",
    "data = pd.concat([data1,data2,data3,data4], axis=0).reset_index(drop=True)\n",
    "data=data[['body','Emotion']]\n",
    "\n",
    "\n",
    "for e in data['Emotion'].values:\n",
    "    row=[0,0]\n",
    "    if e=='Negative' or e=='Very negative':\n",
    "        row=[1,0]\n",
    "    elif e=='Positive' or e=='Very Positive':\n",
    "        row=[0,1]\n",
    "    elif e=='Neutral':\n",
    "        row=[0,1]\n",
    "                \n",
    "    #turning testing_index to testing_index_2cls\n",
    "    os.chdir(path)  \n",
    "                        \n",
    "    name=\"label_emt3_\"+s+\"_cm.csv\"\n",
    "    e=open(name, 'a',newline='')\n",
    "    with e:\n",
    "        writer = csv.writer(e, delimiter=',')\n",
    "        writer.writerow(row)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
