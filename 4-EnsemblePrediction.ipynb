{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-treasurer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use ROC to get cutoff\n",
    "#truth_rand denotes the neg VS non-neg here\n",
    "#Bert prob of neg and pos, are actually neg VS non-neg\n",
    "#ensemble by using ROC for HAN and GAT respectively\n",
    "\n",
    "path_result='C:\\\\Backup of covid project\\\\2cls_negVSnonneg\\\\results\\\\'\n",
    "path_data=\"C:\\\\Backup of covid project\\\\2cls_negVSnonneg\\\\data\\\\\"\n",
    "path_code=\"C:\\\\Backup of covid project\\\\\"\n",
    "\n",
    "\n",
    "import numpy as np \n",
    "import urllib.request \n",
    "import os \n",
    "import csv \n",
    "import requests \n",
    "import time\n",
    "import math\n",
    "import rando\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import re, string, unicodedata\n",
    "import nltk\n",
    "import contractions\n",
    "import inflect\n",
    "import heapq\n",
    "import pickle\n",
    "import warnings\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "filepath=path_result\n",
    "filepath2=path_data\n",
    "filepath3=path_data\n",
    "path=path_data\n",
    "os.chdir(filepath)\n",
    "\n",
    "types=[\"comment\"]\n",
    "years=['2019','2020']\n",
    "#years=['2020']\n",
    "schools = [\"notredame\",\"uofm\",\"columbia\",\"UCSD\",\"berkeley\",\"Harvard\",\"ucla\"]\n",
    "categ={\"notredame\":[1,1,1],\"uofm\":[1,1,0],\"columbia\":[1,0,1],\"dartmouth\":[0,1,1],\n",
    "       \"UCSD\":[1,0,0],\"berkeley\":[0,1,0],\"Harvard\":[0,0,1],\"ucla\":[0,0,0]}\n",
    "\n",
    "#Positive: 1, negative:0\n",
    "#2020:1, 2019:0\n",
    "label_group=[\"label\"]#,\"unlabel\"]\n",
    "months=['08','09','10','11']\n",
    "\n",
    "att_com=['time','id','body','Emotion','emo_pred']\n",
    "drop_com=[\"link_id\",'Topic',\"parent_id\",\"author_fullname\",\"author\",\"gildings\",\"score\",\"subreddit\",\"no_follow\",\"total_awards_received\",\"all_awardings\",\"is_submitter\",\"locked\",\"send_replies\",\"stickied\",]\n",
    "emo=[\"Very Positive\",\"Positive\",\"Neutral\",\"Negative\",\"Very negative\"]\n",
    "top=[\"Covid\",\"Academics\",\"Sports\",\"Campus/Students Life\",\"Social Media\",\"Religion\",\"Politics\",\"Others\"]\n",
    "\n",
    "df = pd.DataFrame(columns = ['body','Emotion','predicted_HAN_neg','predicted_HAN_pos','predicted_BERT_neg','predicted_BERT_pos','truth_label','truth_rand','schoolyear'])\n",
    "#Positive: 1, negative:0\n",
    "for t in types:\n",
    "    for s in schools:\n",
    "        for y in years:\n",
    "            for l in label_group:\n",
    "                f=s+y+'.p'\n",
    "                os.chdir(path_result)\n",
    "                predicted=pickle.load(open(f,'rb'))\n",
    "                from scipy.special import softmax\n",
    "                m=softmax(predicted,axis=1)\n",
    "                pred_HAN=m\n",
    "\n",
    "                f=s+t+y+'label_score.csv'\n",
    "                os.chdir(path_data)\n",
    "                predicted=pd.read_csv(f,skip_blank_lines=True)\n",
    "                predicted=predicted[['emo_pred_neg','emo_pred_pos']].values\n",
    "                for i in range(len(predicted)):\n",
    "                    p0=predicted[i,0]\n",
    "                    #p1=predicted[i,1]\n",
    "                    #predicted[i,0]=p0/(p0+p1)\n",
    "                    predicted[i,1]=1-p0\n",
    "                pred_BERT=predicted\n",
    "\n",
    "                f=s+t+y+l+\".csv\"\n",
    "                os.chdir(path_data)\n",
    "                data=pd.read_csv(f,skip_blank_lines=True)\n",
    "                data=data[['body','Emotion']]\n",
    "\n",
    "                f=\"test_index_\"+s+y+\"_cm.p\"\n",
    "                os.chdir(path_data)\n",
    "                test_index=pickle.load(open(f,'rb'))\n",
    "\n",
    "                f=\"label_emt3_\"+s+y+\"_cm.csv\"\n",
    "                os.chdir(path_data)\n",
    "                rand_truth1=pd.read_csv(f,skip_blank_lines=True, header=None)#.values\n",
    "                rand_truth=np.argmax(rand_truth1.values,axis=1)\n",
    "\n",
    "                w=data.loc[test_index]\n",
    "                w['predicted_HAN_neg']=pred_HAN[test_index,0]\n",
    "                w['predicted_HAN_pos']=pred_HAN[test_index,1]\n",
    "                w['predicted_BERT_neg']=pred_BERT[test_index,0]\n",
    "                w['predicted_BERT_pos']=pred_BERT[test_index,1]\n",
    "\n",
    "                orig_truth=[]\n",
    "                clas_truth=[]\n",
    "                for e in w['Emotion'].values:\n",
    "                    if e=='Negative' or e=='Very negative':\n",
    "                        orig_truth.append(0)\n",
    "                        clas_truth.append(0)\n",
    "                    elif e=='Positive' or e=='Very Positive':\n",
    "                        orig_truth.append(1)\n",
    "                        clas_truth.append(1)\n",
    "                    elif e=='Neutral':\n",
    "                        orig_truth.append(2)\n",
    "                        clas_truth.append(1)\n",
    "                w['truth_label']=np.array(orig_truth)\n",
    "                w['truth_rand']=np.array(clas_truth)\n",
    "                w['schoolyear']=s+y\n",
    "                df = df.append(w,ignore_index = True)\n",
    "\n",
    "#append dartmouth  to df\n",
    "s='dartmouth'\n",
    "f=s+'.p'\n",
    "os.chdir(path_result)\n",
    "predicted=pickle.load(open(f,'rb'))\n",
    "m=softmax(predicted,axis=1)\n",
    "pred_HAN=m\n",
    "\n",
    "f=s+t+'_score.csv'\n",
    "os.chdir(path_data)\n",
    "predicted=pd.read_csv(f,skip_blank_lines=True)#,header=None)\n",
    "#predicted.columns = predicted.columns.astype(str)\n",
    "#predicted.rename(columns={\"6\": \"emo_pred_pos\", \"7\": \"emo_pred_neu\",\"8\": \"emo_pred_neg\"}, inplace = True)\n",
    "predicted=predicted[['emo_pred_neg','emo_pred_pos']].values\n",
    "for i in range(len(predicted)):\n",
    "    p0=predicted[i,0]\n",
    "    #p1=predicted[i,1]\n",
    "    #predicted[i,0]=p0/(p0+p1)\n",
    "    predicted[i,1]=1-p0\n",
    "pred_BERT=predicted\n",
    "\n",
    "f1='dartmouthcomment2019label.csv'\n",
    "f2='dartmouthcomment2019unlabel.csv'\n",
    "f3='dartmouthcomment2020label.csv'\n",
    "f4='dartmouthcomment2020unlabel.csv'\n",
    "os.chdir(path_data)\n",
    "data1=pd.read_csv(f1,skip_blank_lines=True)\n",
    "data1=data1.drop(drop_com, axis=1)\n",
    "data2=pd.read_csv(f2,skip_blank_lines=True)\n",
    "data2=data2.drop(drop_com, axis=1)\n",
    "data3=pd.read_csv(f3,skip_blank_lines=True)\n",
    "data3=data3.drop(drop_com, axis=1)\n",
    "data4=pd.read_csv(f4,skip_blank_lines=True)\n",
    "data4=data4.drop(drop_com, axis=1)\n",
    "data = pd.concat([data1,data2,data3,data4], axis=0).reset_index(drop=True)\n",
    "data=data[['body','Emotion']]\n",
    "\n",
    "f=\"test_index_\"+s+\"_cm.p\"\n",
    "os.chdir(path_data)\n",
    "test_index=pickle.load(open(f,'rb'))\n",
    "\n",
    "f=\"label_emt3_\"+s+\"_cm.csv\"\n",
    "os.chdir(path_data)\n",
    "rand_truth1=pd.read_csv(f,skip_blank_lines=True, header=None)#.values\n",
    "rand_truth=np.argmax(rand_truth1.values,axis=1)\n",
    "\n",
    "w=data.loc[test_index]\n",
    "w['predicted_HAN_neg']=pred_HAN[test_index,0]\n",
    "w['predicted_HAN_pos']=pred_HAN[test_index,1]\n",
    "w['predicted_BERT_neg']=pred_BERT[test_index,0]\n",
    "w['predicted_BERT_pos']=pred_BERT[test_index,1]\n",
    "\n",
    "orig_truth=[]\n",
    "for e in w['Emotion'].values:\n",
    "    if e=='Negative' or e=='Very negative':\n",
    "        orig_truth.append(0)\n",
    "    elif e=='Positive' or e=='Very Positive':\n",
    "        orig_truth.append(1)\n",
    "    elif e=='Neutral':\n",
    "        orig_truth.append(2)\n",
    "w['truth_label']=np.array(orig_truth)\n",
    "w['truth_rand']=rand_truth[test_index]\n",
    "w['schoolyear']=s\n",
    "df = df.append(w,ignore_index = True)\n",
    "\n",
    "#Define the validation dataset\n",
    "#kfold=5#k fold validation, need to be divisible by 50\n",
    "df['vali']=int(0)\n",
    "schoolyears=[\"notredame2019\",\"notredame2020\",\"uofm2019\",\"uofm2020\",\"columbia2019\",\"columbia2020\",\"UCSD2019\",\"UCSD2020\",\"berkeley2019\",\"berkeley2020\",\"Harvard2019\",\"Harvard2020\",\"ucla2019\",\"ucla2020\",\"dartmouth\"]\n",
    "\n",
    "#vali==1 means its testing set instead of validation set!\n",
    "k=1\n",
    "n_vali=25#best\n",
    "n_neu=int(31*n_vali/50)\n",
    "n_left=n_vali-n_neu\n",
    "v_neg=np.array([n_vali,n_vali,n_vali,n_vali,n_vali,n_vali,n_vali,n_vali,n_vali,n_vali,n_vali,n_vali,n_vali,n_vali,n_vali])\n",
    "v_neu=np.array([n_neu,n_neu,n_neu,n_neu,n_neu,n_neu,n_neu,n_neu,n_neu,n_neu,n_neu,n_neu,n_neu,n_neu,n_neu])\n",
    "v_pos=np.array([n_left,n_left,n_left,n_left,n_left,n_left,n_left,n_left,n_left,n_left,n_left,n_left,n_left,n_left,n_left])\n",
    "for d in range(len(df['schoolyear'])):\n",
    "    if df['truth_label'].iloc[d]==0 and v_neg[schoolyears.index(df['schoolyear'].iloc[d])]>0:\n",
    "        df.at[d, 'vali']=int(k);\n",
    "        v_neg[schoolyears.index(df['schoolyear'].iloc[d])]-=1\n",
    "    elif df['truth_label'].iloc[d]==1 and v_pos[schoolyears.index(df['schoolyear'].iloc[d])]>0:\n",
    "        df.at[d, 'vali']=int(k);\n",
    "        v_pos[schoolyears.index(df['schoolyear'].iloc[d])]-=1\n",
    "    elif df['truth_label'].iloc[d]==2 and v_neu[schoolyears.index(df['schoolyear'].iloc[d])]>0:\n",
    "        df.at[d, 'vali']=int(k);\n",
    "        v_neu[schoolyears.index(df['schoolyear'].iloc[d])]-=1\n",
    "\n",
    "\n",
    "    \n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from matplotlib import pyplot\n",
    "truth=np.array(df.loc[(df.vali==0)]['truth_rand'],dtype=int)\n",
    "han=np.array(df.loc[(df.vali==0)]['predicted_HAN_pos'],dtype=float)\n",
    "fpr, tpr, thresholds = roc_curve(truth, han)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "pyplot.plot(fpr, tpr, marker='.', label='GAT')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "gmeans = sqrt(tpr * (1-fpr))\n",
    "# locate the index of the largest g-mean\n",
    "ix = argmax(gmeans)\n",
    "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "cutoff_han=thresholds[ix]\n",
    "\n",
    "han=np.array(df.loc[(df.vali==0)]['predicted_BERT_pos'],dtype=float)\n",
    "fpr, tpr, thresholds = roc_curve(truth, han)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "pyplot.plot(fpr, tpr, marker='.', label='BERT')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "gmeans = sqrt(tpr * (1-fpr))\n",
    "# locate the index of the largest g-mean\n",
    "ix = argmax(gmeans)\n",
    "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "cutoff_bert=thresholds[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize all probability using cut0ff\n",
    "\n",
    "df['pred_han_neg_norm']=int(0)\n",
    "df['pred_han_pos_norm']=int(0)\n",
    "df['pred_bert_neg_norm']=int(0)\n",
    "df['pred_bert_pos_norm']=int(0)\n",
    "\n",
    "for d in range(len(df['body'])):\n",
    "    if df.iloc[d]['predicted_HAN_pos']>=cutoff_han:\n",
    "        newpos=0.5*(df.iloc[d]['predicted_HAN_pos']-cutoff_han)/(1-cutoff_han)+0.5\n",
    "    elif df.iloc[d]['predicted_HAN_pos']<cutoff_han:\n",
    "        newpos=0.5*df.iloc[d]['predicted_HAN_pos']/cutoff_han\n",
    "    df.iloc[d, df.columns.get_loc('pred_han_pos_norm')]=newpos\n",
    "    df.iloc[d, df.columns.get_loc('pred_han_neg_norm')]=1-newpos\n",
    "    \n",
    "    if df.iloc[d]['predicted_BERT_pos']>=cutoff_bert:\n",
    "        newpos=0.5*(df.iloc[d]['predicted_BERT_pos']-cutoff_bert)/(1-cutoff_bert)+0.5\n",
    "    elif df.iloc[d]['predicted_BERT_pos']<cutoff_bert:\n",
    "        newpos=0.5*df.iloc[d]['predicted_BERT_pos']/cutoff_bert\n",
    "    df.iloc[d, df.columns.get_loc('pred_bert_pos_norm')]=newpos\n",
    "    df.iloc[d, df.columns.get_loc('pred_bert_neg_norm')]=1-newpos\n",
    "print(d)\n",
    "#(df)#.iloc[1])#['predicted_HAN_neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "#genearte figure 3\n",
    "x1=np.array(df[(df.truth_rand==0) & (df.vali==1)].predicted_HAN_neg)\n",
    "x2=np.array(df[(df.truth_rand==0) & (df.vali==1)].predicted_BERT_neg)\n",
    "\n",
    "x3=np.array(df[(df.truth_rand==1) & (df.vali==1)].predicted_HAN_pos)\n",
    "x4=np.array(df[(df.truth_rand==1) & (df.vali==1)].predicted_BERT_pos)\n",
    "\n",
    "x1=np.array(df[(df.truth_rand==0) & (df.vali==1)].pred_han_neg_norm)\n",
    "x2=np.array(df[(df.truth_rand==0) & (df.vali==1)].pred_bert_neg_norm)\n",
    "\n",
    "x3=np.array(df[(df.truth_rand==1) & (df.vali==1)].pred_han_pos_norm)\n",
    "x4=np.array(df[(df.truth_rand==1) & (df.vali==1)].pred_bert_pos_norm)\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "os.chdir(path_result)\n",
    "\n",
    "fig = plt.figure()\n",
    "#ax = fig.add_subplot()\n",
    "l1=[0,1]\n",
    "#plt.plot(x2, x1)\n",
    "matplotlib.pyplot.plot(x1, x2, 'bo')\n",
    "matplotlib.pyplot.plot(l1, l1, 'r-')\n",
    "print(numpy.corrcoef(x1, x2)[0, 1])\n",
    "#matplotlib.pyplot.set_aspect('equal', 'box')\n",
    "#.pyplot.gca().set_aspect('equal')\n",
    "matplotlib.pyplot.axis('square')\n",
    "matplotlib.pyplot.gca().spines['top'].set_visible(False)\n",
    "matplotlib.pyplot.gca().spines['right'].set_visible(False)\n",
    "plt.xlabel(\"predicted probability by GAT\")\n",
    "plt.ylabel(\"predicted probability by RoBERTa\")\n",
    "#ax.text(0.8, 0.1, 'Corr='+str(np.round(numpy.corrcoef(x1, x2)[0, 1],4)),bbox={'facecolor': 'white', 'alpha': 0.5, 'pad': 10})\n",
    "matplotlib.pyplot.savefig('plot3.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "#ax = fig.add_subplo3t()\n",
    "matplotlib.pyplot.plot(x3, x4, 'bo')\n",
    "matplotlib.pyplot.plot(l1, l1, 'r-')\n",
    "print(numpy.corrcoef(x3, x4)[0, 1])\n",
    "matplotlib.pyplot.axis('square')\n",
    "matplotlib.pyplot.gca().spines['top'].set_visible(False)\n",
    "matplotlib.pyplot.gca().spines['right'].set_visible(False)\n",
    "plt.xlabel(\"predicted probability by GAT\")\n",
    "plt.ylabel(\"predicted probability by RoBERTa\")\n",
    "#ax.text(0.8, 0.1, 'Corr='+str(np.round(numpy.corrcoef(x3, x4)[0, 1],4)),bbox={'facecolor': 'white', 'alpha': 0.5, 'pad': 10})\n",
    "matplotlib.pyplot.savefig('plot4.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using logistic regression to get prediction\n",
    "#RUN PREVIOUS CODE BEFORE RUNNIGN THIS ONE\n",
    "#copy paste regression coefficient to step 5 notebook\n",
    "\n",
    "# split into train/test sets\n",
    "trainX=np.transpose(np.vstack((np.array(df.loc[(df.vali==0)]['pred_han_pos_norm'],dtype=float), \n",
    "                np.array(df.loc[(df.vali==0)]['pred_bert_pos_norm'],dtype=float))))\n",
    "testX=np.transpose(np.vstack((np.array(df.loc[(df.vali==1)]['pred_han_pos_norm'],dtype=float), \n",
    "                np.array(df.loc[(df.vali==1)]['pred_bert_pos_norm'],dtype=float))))\n",
    "trainy=np.array(df.loc[(df.vali==0)]['truth_rand'],dtype=float)\n",
    "testy =np.array(df.loc[(df.vali==1)]['truth_rand'],dtype=float)\n",
    "# fit a model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(trainX, trainy)\n",
    "print([model.intercept_,model.coef_])\n",
    "w=(model.coef_[0])\n",
    "weights=[]\n",
    "pred=[]\n",
    "for s in schoolyears:\n",
    "    # split into train/test sets\n",
    "    trainX=np.transpose(np.vstack((np.array(df.loc[(df.vali==0) & (df.schoolyear==s)]['pred_han_pos_norm'],dtype=float), \n",
    "                np.array(df.loc[(df.vali==0) & (df.schoolyear==s)]['pred_bert_pos_norm'],dtype=float))))\n",
    "    testX=np.transpose(np.vstack((np.array(df.loc[(df.vali==1) & (df.schoolyear==s)]['pred_han_pos_norm'],dtype=float), \n",
    "                np.array(df.loc[(df.vali==1) & (df.schoolyear==s)]['pred_bert_pos_norm'],dtype=float))))\n",
    "    trainy=np.array(df.loc[(df.vali==0) & (df.schoolyear==s)]['truth_rand'],dtype=float)\n",
    "    testy =np.array(df.loc[(df.vali==1) & (df.schoolyear==s)]['truth_rand'],dtype=float)\n",
    "    # fit a model\n",
    "    #model = LogisticRegression(solver='lbfgs')#,fit_intercept=False)\n",
    "    #model.fit(trainX, trainy)\n",
    "    a=np.transpose(np.vstack((np.array(df.loc[(df.schoolyear==s)]['pred_han_pos_norm'],dtype=float), \n",
    "                              np.array(df.loc[(df.schoolyear==s)]['pred_bert_pos_norm'],dtype=float))))\n",
    "    pred+=(list(model.predict(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN PREVIOUS CODE BEFORE THIS ONE \n",
    "#get testing result\n",
    "\n",
    "path_result='C:\\\\Backup of covid project\\\\2cls_negVSnonneg\\\\results\\\\'\n",
    "path_data=\"C:\\\\Backup of covid project\\\\2cls_negVSnonneg\\\\data\\\\\"\n",
    "path_code=\"C:\\\\Backup of covid project\\\\\"\n",
    "\n",
    "import numpy as np \n",
    "import urllib.request \n",
    "import os \n",
    "import csv \n",
    "import requests \n",
    "import time\n",
    "import math\n",
    "import rando\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import re, string, unicodedata\n",
    "import nltk\n",
    "import contractions\n",
    "import inflect\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "from string import punctuation\n",
    "from autocorrect import Speller\n",
    "from autocorrect import spell\n",
    "import heapq\n",
    "import pickle\n",
    "import warnings\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "#import tensorflow_hub as hub\n",
    "#import tensorflow_text\n",
    "\n",
    "filepath=path_result\n",
    "filepath2=path_data\n",
    "filepath3=path_data\n",
    "path=path_data\n",
    "os.chdir(filepath)\n",
    "\n",
    "types=[\"comment\"]\n",
    "years=['2019','2020']\n",
    "#years=['2020']\n",
    "schools = [\"notredame\",\"uofm\",\"columbia\",\"UCSD\",\"berkeley\",\"Harvard\",\"ucla\"]\n",
    "categ={\"notredame\":[1,1,1],\"uofm\":[1,1,0],\"columbia\":[1,0,1],\"dartmouth\":[0,1,1],\n",
    "       \"UCSD\":[1,0,0],\"berkeley\":[0,1,0],\"Harvard\":[0,0,1],\"ucla\":[0,0,0]}\n",
    "\n",
    "#Positive: 1, negative:0\n",
    "#2020:1, 2019:0\n",
    "label_group=[\"label\"]#,\"unlabel\"]\n",
    "months=['08','09','10','11']\n",
    "\n",
    "att_com=['time','id','body','Emotion','emo_pred']\n",
    "drop_com=[\"link_id\",'Topic',\"parent_id\",\"author_fullname\",\"author\",\"gildings\",\"score\",\"subreddit\",\"no_follow\",\"total_awards_received\",\"all_awardings\",\"is_submitter\",\"locked\",\"send_replies\",\"stickied\",]\n",
    "emo=[\"Very Positive\",\"Positive\",\"Neutral\",\"Negative\",\"Very negative\"]\n",
    "top=[\"Covid\",\"Academics\",\"Sports\",\"Campus/Students Life\",\"Social Media\",\"Religion\",\"Politics\",\"Others\"]\n",
    "\n",
    "TP_HAN=[]\n",
    "TN_HAN=[]\n",
    "CR_HAN=[]\n",
    "Pre_HAN=[]\n",
    "Rec_HAN=[]\n",
    "Spe_HAN=[]\n",
    "\n",
    "TP_BERT=[]\n",
    "TN_BERT=[]\n",
    "CR_BERT=[]\n",
    "Pre_BERT=[]\n",
    "Rec_BERT=[]\n",
    "Spe_BERT=[]\n",
    "      \n",
    "        \n",
    "#Find labels from probability for three methods\n",
    "df['pred_esm']=0\n",
    "df['pred_HAN']=0\n",
    "df['pred_BERT']=0\n",
    "\n",
    "\n",
    "schoolyears=[\"notredame2019\",\"notredame2020\",\"uofm2019\",\"uofm2020\",\"columbia2019\",\"columbia2020\",\"UCSD2019\",\"UCSD2020\",\"berkeley2019\",\"berkeley2020\",\"Harvard2019\",\"Harvard2020\",\"ucla2019\",\"ucla2020\",\"dartmouth\"]\n",
    "      \n",
    "\n",
    "#Analyse for classification rate for testing set\n",
    "\n",
    "for d in range(len(df['schoolyear'])):\n",
    "    negHAN=df['pred_han_neg_norm'].iloc[d]\n",
    "    posHAN=df['pred_han_pos_norm'].iloc[d]\n",
    "    negBERT=df['pred_bert_neg_norm'].iloc[d]\n",
    "    posBERT=df['pred_bert_pos_norm'].iloc[d]\n",
    "    \n",
    "    if posHAN>=0.5:\n",
    "        #df['pred_HAN'].iloc[d]=0\n",
    "        df.iloc[d, df.columns.get_loc('pred_HAN')] =1\n",
    "    elif posHAN<=0.5:\n",
    "        #df['pred_HAN'].iloc[d]=1\n",
    "        df.iloc[d, df.columns.get_loc('pred_HAN')] =0\n",
    "    if posBERT>=0.5:\n",
    "        #df['pred_BERT'].iloc[d]=0\n",
    "        df.iloc[d, df.columns.get_loc('pred_BERT')] =1\n",
    "    elif posBERT<=0.5:\n",
    "        #df['pred_BERT'].iloc[d]=1\n",
    "        df.iloc[d, df.columns.get_loc('pred_BERT')] =0\n",
    "        \n",
    "    df.iloc[d, df.columns.get_loc('pred_esm')]=pred[d]\n",
    "    \n",
    "CR_HAN=[]\n",
    "CR_BERT=[]\n",
    "CR_esm=[]\n",
    "    \n",
    "F1_HAN=[]\n",
    "F1_BERT=[]\n",
    "F1_esm=[]\n",
    "\n",
    "Pre_HAN=[]\n",
    "Pre_BERT=[]\n",
    "Pre_esm=[]\n",
    "\n",
    "Rec_HAN=[]\n",
    "Rec_BERT=[]\n",
    "Rec_esm=[]\n",
    "\n",
    "Spe_HAN=[]\n",
    "Spe_BERT=[]\n",
    "Spe_esm=[]\n",
    "    \n",
    "for s in schoolyears:\n",
    "    CR_esm.append(sum(df.loc[(df.schoolyear==s) & (df.vali==k)]['truth_rand']==df.loc[(df.schoolyear==s) & (df.vali==k)]['pred_esm'])/len(df.loc[(df.schoolyear==s) & (df.vali==k)]['truth_rand']))\n",
    "    CR_BERT.append(sum(df.loc[(df.schoolyear==s) & (df.vali==k)]['truth_rand']==df.loc[(df.schoolyear==s) & (df.vali==k)]['pred_BERT'])/len(df.loc[(df.schoolyear==s) & (df.vali==k)]['truth_rand']))\n",
    "    CR_HAN.append(sum(df.loc[(df.schoolyear==s) & (df.vali==k)]['truth_rand']==df.loc[(df.schoolyear==s) & (df.vali==k)]['pred_HAN'])/len(df.loc[(df.schoolyear==s) & (df.vali==k)]['truth_rand']))\n",
    "        \n",
    "    #calculation for HAN\n",
    "    Predicted_Neg=len(df.loc[(df.schoolyear==s) & (df.vali==k) & (df.pred_HAN==0)]['schoolyear'])\n",
    "    Predicted_Pos=len(df.loc[(df.schoolyear==s) & (df.vali==k) & (df.pred_HAN==1)]['schoolyear'])\n",
    "    Truth_Neg=len(df.loc[(df.schoolyear==s) & (df.vali==k) & (df.truth_rand==0)]['schoolyear'])\n",
    "    Truth_Pos=len(df.loc[(df.schoolyear==s) & (df.vali==k) & (df.truth_rand==1)]['schoolyear'])\n",
    "            \n",
    "    False_Pos=len(df.loc[(df.schoolyear==s) & (df.vali==k) & (df.pred_HAN==1) & (df.truth_rand==0)]['schoolyear'])\n",
    "    False_Neg=len(df.loc[(df.schoolyear==s) & (df.vali==k) & (df.pred_HAN==0) & (df.truth_rand==1)]['schoolyear'])\n",
    "    True_Pos=len(df.loc[(df.schoolyear==s) & (df.vali==k) & (df.pred_HAN==1) & (df.truth_rand==1)]['schoolyear'])\n",
    "    True_Neg=len(df.loc[(df.schoolyear==s) & (df.vali==k) & (df.pred_HAN==0) & (df.truth_rand==0)]['schoolyear'])\n",
    "    \n",
    "    Pre_HAN.append(True_Pos/Predicted_Pos)\n",
    "    Rec_HAN.append(True_Pos/Truth_Pos)\n",
    "    Spe_HAN.append(True_Neg/Truth_Neg)\n",
    "    \n",
    "    #calculation for BERT\n",
    "    Predicted_Neg=len(df.loc[(df.schoolyear==s) & (df.vali==k) & (df.pred_BERT==0)]['schoolyear'])\n",
    "    Predicted_Pos=len(df.loc[(df.schoolyear==s) & (df.vali==k) & (df.pred_BERT==1)]['schoolyear'])\n",
    "    Truth_Neg=len(df.loc[(df.schoolyear==s) & (df.vali==k) & (df.truth_rand==0)]['schoolyear'])\n",
    "    Truth_Pos=len(df.loc[(df.schoolyear==s) & (df.vali==k) & (df.truth_rand==1)]['schoolyear'])\n",
    "            \n",
    "    False_Pos=len(df.loc[(df.schoolyear==s) & (df.vali==k) & (df.pred_BERT==1) & (df.truth_rand==0)]['schoolyear'])\n",
    "    False_Neg=len(df.loc[(df.schoolyear==s) & (df.vali==k) & (df.pred_BERT==0) & (df.truth_rand==1)]['schoolyear'])\n",
    "    True_Pos=len(df.loc[(df.schoolyear==s) & (df.vali==k) & (df.pred_BERT==1) & (df.truth_rand==1)]['schoolyear'])\n",
    "    True_Neg=len(df.loc[(df.schoolyear==s) & (df.vali==k) & (df.pred_BERT==0) & (df.truth_rand==0)]['schoolyear'])\n",
    "    \n",
    "    Pre_BERT.append(True_Pos/Predicted_Pos)\n",
    "    Rec_BERT.append(True_Pos/Truth_Pos)\n",
    "    Spe_BERT.append(True_Neg/Truth_Neg)\n",
    "    \n",
    "    #calculation for esm\n",
    "    Predicted_Neg=len(df.loc[(df.schoolyear==s) & (df.vali==k) & (df.pred_esm==0)]['schoolyear'])\n",
    "    Predicted_Pos=len(df.loc[(df.schoolyear==s) & (df.vali==k) & (df.pred_esm==1)]['schoolyear'])\n",
    "    Truth_Neg=len(df.loc[(df.schoolyear==s) & (df.vali==k) & (df.truth_rand==0)]['schoolyear'])\n",
    "    Truth_Pos=len(df.loc[(df.schoolyear==s) & (df.vali==k) & (df.truth_rand==1)]['schoolyear'])\n",
    "            \n",
    "    False_Pos=len(df.loc[(df.schoolyear==s) & (df.vali==k) & (df.pred_esm==1) & (df.truth_rand==0)]['schoolyear'])\n",
    "    False_Neg=len(df.loc[(df.schoolyear==s) & (df.vali==k) & (df.pred_esm==0) & (df.truth_rand==1)]['schoolyear'])\n",
    "    True_Pos=len(df.loc[(df.schoolyear==s) & (df.vali==k) & (df.pred_esm==1) & (df.truth_rand==1)]['schoolyear'])\n",
    "    True_Neg=len(df.loc[(df.schoolyear==s) & (df.vali==k) & (df.pred_esm==0) & (df.truth_rand==0)]['schoolyear'])\n",
    "    \n",
    "    Pre_esm.append(True_Pos/Predicted_Pos)\n",
    "    Rec_esm.append(True_Pos/Truth_Pos)\n",
    "    Spe_esm.append(True_Neg/Truth_Neg)\n",
    "\n",
    "CR_esm.append(sum(df.loc[(df.vali==k)]['truth_rand']==df.loc[(df.vali==k)]['pred_esm'])/len(df.loc[(df.vali==k)]['truth_rand']))\n",
    "CR_BERT.append(sum(df.loc[(df.vali==k)]['truth_rand']==df.loc[(df.vali==k)]['pred_BERT'])/len(df.loc[(df.vali==k)]['truth_rand']))\n",
    "CR_HAN.append(sum(df.loc[(df.vali==k)]['truth_rand']==df.loc[(df.vali==k)]['pred_HAN'])/len(df.loc[(df.vali==k)]['truth_rand']))\n",
    "\n",
    "#calculation for HAN\n",
    "Predicted_Neg=len(df.loc[(df.vali==k) & (df.pred_HAN==0)]['schoolyear'])\n",
    "Predicted_Pos=len(df.loc[(df.vali==k) & (df.pred_HAN==1)]['schoolyear'])\n",
    "Truth_Neg=len(df.loc[(df.vali==k) & (df.truth_rand==0)]['schoolyear'])\n",
    "Truth_Pos=len(df.loc[(df.vali==k) & (df.truth_rand==1)]['schoolyear'])\n",
    "\n",
    "False_Pos=len(df.loc[(df.vali==k) & (df.pred_HAN==1) & (df.truth_rand==0)]['schoolyear'])\n",
    "False_Neg=len(df.loc[(df.vali==k) & (df.pred_HAN==0) & (df.truth_rand==1)]['schoolyear'])\n",
    "True_Pos=len(df.loc[(df.vali==k) & (df.pred_HAN==1) & (df.truth_rand==1)]['schoolyear'])\n",
    "True_Neg=len(df.loc[(df.vali==k) & (df.pred_HAN==0) & (df.truth_rand==0)]['schoolyear'])\n",
    "\n",
    "Pre_HAN.append(True_Pos/Predicted_Pos)\n",
    "Rec_HAN.append(True_Pos/Truth_Pos)\n",
    "Spe_HAN.append(True_Neg/Truth_Neg)\n",
    "\n",
    "#calculation for BERT\n",
    "Predicted_Neg=len(df.loc[(df.vali==k) & (df.pred_BERT==0)]['schoolyear'])\n",
    "Predicted_Pos=len(df.loc[(df.vali==k) & (df.pred_BERT==1)]['schoolyear'])\n",
    "Truth_Neg=len(df.loc[(df.vali==k) & (df.truth_rand==0)]['schoolyear'])\n",
    "Truth_Pos=len(df.loc[(df.vali==k) & (df.truth_rand==1)]['schoolyear'])\n",
    "\n",
    "False_Pos=len(df.loc[(df.vali==k) & (df.pred_BERT==1) & (df.truth_rand==0)]['schoolyear'])\n",
    "False_Neg=len(df.loc[(df.vali==k) & (df.pred_BERT==0) & (df.truth_rand==1)]['schoolyear'])\n",
    "True_Pos=len(df.loc[(df.vali==k) & (df.pred_BERT==1) & (df.truth_rand==1)]['schoolyear'])\n",
    "True_Neg=len(df.loc[(df.vali==k) & (df.pred_BERT==0) & (df.truth_rand==0)]['schoolyear'])\n",
    "\n",
    "Pre_BERT.append(True_Pos/Predicted_Pos)\n",
    "Rec_BERT.append(True_Pos/Truth_Pos)\n",
    "Spe_BERT.append(True_Neg/Truth_Neg)\n",
    "\n",
    "#calculation for esm\n",
    "Predicted_Neg=len(df.loc[(df.vali==k) & (df.pred_esm==0)]['schoolyear'])\n",
    "Predicted_Pos=len(df.loc[(df.vali==k) & (df.pred_esm==1)]['schoolyear'])\n",
    "Truth_Neg=len(df.loc[(df.vali==k) & (df.truth_rand==0)]['schoolyear'])\n",
    "Truth_Pos=len(df.loc[(df.vali==k) & (df.truth_rand==1)]['schoolyear'])\n",
    "\n",
    "False_Pos=len(df.loc[(df.vali==k) & (df.pred_esm==1) & (df.truth_rand==0)]['schoolyear'])\n",
    "False_Neg=len(df.loc[(df.vali==k) & (df.pred_esm==0) & (df.truth_rand==1)]['schoolyear'])\n",
    "True_Pos=len(df.loc[(df.vali==k) & (df.pred_esm==1) & (df.truth_rand==1)]['schoolyear'])\n",
    "True_Neg=len(df.loc[(df.vali==k) & (df.pred_esm==0) & (df.truth_rand==0)]['schoolyear'])\n",
    "\n",
    "Pre_esm.append(True_Pos/Predicted_Pos)\n",
    "Rec_esm.append(True_Pos/Truth_Pos)\n",
    "Spe_esm.append(True_Neg/Truth_Neg)\n",
    "\n",
    "F1_HAN=2*np.divide(np.multiply(Pre_HAN,Rec_HAN),np.add(Pre_HAN,Rec_HAN))\n",
    "F1_BERT=2*np.divide(np.multiply(Pre_BERT,Rec_BERT),np.add(Pre_BERT,Rec_BERT))\n",
    "F1_esm=2*np.divide(np.multiply(Pre_esm,Rec_esm),np.add(Pre_esm,Rec_esm))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-minneapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run previous one before running this one \n",
    "#save prediction results in file \"figure4\"\n",
    "\n",
    "sc=['metric','method',\"notredame2019\",\"notredame2020\",\"uofm2019\",\"uofm2020\",\"columbia2019\",\"columbia2020\",\"UCSD2019\",\"UCSD2020\",\"berkeley2019\",\"berkeley2020\",\"Harvard2019\",\"Harvard2020\",\"ucla2019\",\"ucla2020\",\"dartmouth\",'overall']\n",
    "\n",
    "dat=[['CR']+['HAN']+[str(c) for c in CR_HAN]]\n",
    "line=['CR']+['BERT']+[str(c) for c in CR_BERT];dat.append(line);\n",
    "line=['CR']+['esm']+[str(c) for c in CR_esm];dat.append(line);\n",
    "\n",
    "line=['F1']+['HAN']+[str(c) for c in F1_HAN];dat.append(line);\n",
    "line=['F1']+['BERT']+[str(c) for c in F1_BERT];dat.append(line);\n",
    "line=['F1']+['esm']+[str(c) for c in F1_esm];dat.append(line);\n",
    "\n",
    "line=['Pre']+['HAN']+[str(c) for c in Pre_HAN];dat.append(line);\n",
    "line=['Pre']+['BERT']+[str(c) for c in Pre_BERT];dat.append(line);\n",
    "line=['Pre']+['esm']+[str(c) for c in Pre_esm];dat.append(line);\n",
    "\n",
    "line=['Rec']+['HAN']+[str(c) for c in Rec_HAN];dat.append(line);\n",
    "line=['Rec']+['BERT']+[str(c) for c in Rec_BERT];dat.append(line);\n",
    "line=['Rec']+['esm']+[str(c) for c in Rec_esm];dat.append(line);\n",
    "\n",
    "line=['Spe']+['HAN']+[str(c) for c in Spe_HAN];dat.append(line);\n",
    "line=['Spe']+['BERT']+[str(c) for c in Spe_BERT];dat.append(line);\n",
    "line=['Spe']+['esm']+[str(c) for c in Spe_esm];dat.append(line);\n",
    "\n",
    "#print(dat)\n",
    "dff=pd.DataFrame(dat,columns=sc)\n",
    "os.chdir(path_result)\n",
    "dff.to_csv(path_result+'figure4.csv', index = False, header=True)\n",
    "print(dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#format it to table\n",
    "#the sequence of methods are gat, bert, ens, which are different from paper\n",
    "#change the sequence you copy paste\n",
    "\n",
    "dff=dff.reset_index()\n",
    "dff['dartmouth2019']=dff['dartmouth']\n",
    "dff['dartmouth2020']=''\n",
    "dff['overall2019']=dff['overall']\n",
    "dff['overall2020']=''\n",
    "metrics=['CAR\\\\textsuperscript{*} ','F1\\\\textsuperscript{$\\\\dagger$} ','specificity ',\n",
    "        'precision\\\\textsuperscript{$\\\\ddagger$} ','recall\\\\textsuperscript{${\\\\dagger\\\\dagger}$} ']\n",
    "metric_name=['CR',\"F1\",'Pre',\"Rec\",'Spe']\n",
    "years=['2019','2020']\n",
    "methods=['GAT','bert','ens']\n",
    "schoolyears2019=[\"ucla2019\",\"UCSD2019\",\"berkeley2019\",\"uofm2019\",\"Harvard2019\",\"columbia2019\",\"dartmouth2019\",\"notredame2019\",'overall2019']\n",
    "schoolyears2020=[\"ucla2020\",\"UCSD2020\",\"berkeley2020\",\"uofm2020\",\"Harvard2020\",\"columbia2020\",\"dartmouth2020\",\"notredame2020\",'overall2020']\n",
    "\n",
    "for me in range(len(methods)):\n",
    "    id=me-3\n",
    "    for m in range(len(metrics)):\n",
    "        id+=3\n",
    "        for y in years:\n",
    "            if y=='2019':\n",
    "                line=metrics[m]+'& 2019 '\n",
    "                for s in schoolyears2019:\n",
    "                    if len(dff[s][m])>0:\n",
    "                        new='{:.3f}'.format(round(float(dff[s][id]), 3))\n",
    "                    else:\n",
    "                        new=''\n",
    "                    line=line+'& '+new\n",
    "            elif y=='2020':\n",
    "                line='    & 2020 '\n",
    "                for s in schoolyears2020:\n",
    "                    if len(dff[s][m])>0:\n",
    "                        new='{:.3f}'.format(round(float(dff[s][id]), 3))\n",
    "                    else:\n",
    "                        new=''\n",
    "                    line=line+'& '+new\n",
    "            line=line+'\\\\\\\\'\n",
    "            print(line)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
