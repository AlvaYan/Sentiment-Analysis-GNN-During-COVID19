{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "surrounded-maple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\owner\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:133: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n",
      "120000\n",
      "125000\n",
      "130000\n",
      "135000\n",
      "140000\n",
      "145000\n",
      "150000\n",
      "155000\n",
      "160000\n",
      "165000\n",
      "df_all finished\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "147000\n",
      "148000\n",
      "149000\n",
      "150000\n",
      "151000\n",
      "152000\n",
      "153000\n",
      "154000\n",
      "155000\n",
      "156000\n",
      "157000\n",
      "158000\n",
      "159000\n",
      "160000\n",
      "161000\n",
      "162000\n",
      "163000\n",
      "164000\n",
      "165000\n"
     ]
    }
   ],
   "source": [
    "#Get data ready for GLMM for ensemble methods\n",
    "#copy paste ROC cutoff, logistic regression coefficient from step 4 before running this one\n",
    "\n",
    "#------------import predictions of GAT and BERT------------------\n",
    "#These paths are different from it in  \n",
    "path_result='C:\\\\Backup of covid project\\\\2cls_CScombined_negVSnonneg\\\\results_Cmodel\\\\'\n",
    "path_data=\"C:\\\\Backup of covid project\\\\2cls_CScombined_negVSnonneg\\\\data\\\\\"\n",
    "path_code=\"C:\\\\Backup of covid project\\\\2cls_CScombined_negVSnonneg\\\\\"\n",
    "\n",
    "#C:\\Backup of covid project\\2cls_CScombined_negVSnonneg\n",
    "import numpy as np \n",
    "import urllib.request \n",
    "import os \n",
    "import csv \n",
    "import requests \n",
    "import time\n",
    "import math\n",
    "import rando\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import re, string, unicodedata\n",
    "import nltk\n",
    "import contractions\n",
    "import inflect\n",
    "import heapq\n",
    "import pickle\n",
    "import warnings\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "os.chdir(path_data)\n",
    "\n",
    "types=[\"comment\"]\n",
    "years=['2019','2020']\n",
    "schools = [\"notredame\",\"uofm\",\"columbia\",\"UCSD\",\"berkeley\",\"Harvard\",\"ucla\"]\n",
    "categ={\"notredame\":[1,1,1],\"uofm\":[1,1,0],\"columbia\":[1,0,1],\"dartmouth\":[0,1,1],\n",
    "       \"UCSD\":[1,0,0],\"berkeley\":[0,1,0],\"Harvard\":[0,0,1],\"ucla\":[0,0,0]}\n",
    "label_group=[\" \"]\n",
    "months=['08','09','10','11']\n",
    "t_com=['time','id','body','Emotion','emo_pred']\n",
    "drop_com=[\"link_id\",'Topic',\"parent_id\",\"author_fullname\",\"author\",\"gildings\",\"score\",\"subreddit\",\"no_follow\",\"total_awards_received\",\"all_awardings\",\"is_submitter\",\"locked\",\"send_replies\",\"stickied\",]\n",
    "emo=[\"Very Positive\",\"Positive\",\"Neutral\",\"Negative\",\"Very negative\"]\n",
    "\n",
    "df_all = pd.DataFrame(columns = ['Emotion','predicted_HAN_neg','predicted_HAN_pos','predicted_BERT_neg','predicted_BERT_pos','truth_label','truth_rand','school','year','schoolyear'])\n",
    "ii=0\n",
    "for t in types:\n",
    "    for s in schools:\n",
    "        for y in years:\n",
    "            print(ii)\n",
    "            ii+=1\n",
    "            f=s+y+'.p'\n",
    "            os.chdir(path_result)\n",
    "            predicted=pickle.load(open(f,'rb'))\n",
    "            from scipy.special import softmax\n",
    "            m=softmax(predicted,axis=1)\n",
    "            pred_HAN=m\n",
    "            \n",
    "            f=\"label_emt3_\"+s+y+\".csv\"\n",
    "            os.chdir(path_data)\n",
    "            rand_truth1=pd.read_csv(f,skip_blank_lines=True, header=None)#.values\n",
    "            rand_truth=np.argmax(rand_truth1.values,axis=1)\n",
    "                \n",
    "            data = pd.DataFrame(columns = ['Emotion'])\n",
    "            predicted = pd.DataFrame(columns = ['emo_pred_neg','emo_pred_pos'])\n",
    "            \n",
    "            for l in label_group:\n",
    "                f=s+y+\".csv\"\n",
    "                os.chdir(path_data)\n",
    "                dat=pd.read_csv(f,skip_blank_lines=True)\n",
    "                data=data.append(dat,ignore_index = True)\n",
    "\n",
    "                f=s+y+'_score.csv'\n",
    "                os.chdir(path_data)\n",
    "                predicted1=pd.read_csv(f,skip_blank_lines=True)\n",
    "                predicted=predicted.append(predicted1[['emo_pred_neg','emo_pred_pos']],ignore_index = True)\n",
    "            \n",
    "            predicted=predicted[['emo_pred_neg','emo_pred_pos']].values\n",
    "            for i in range(len(predicted)):\n",
    "                p0=predicted[i,0]\n",
    "                #predicted[i,0]=p[0]/(p[0]+p[1])\n",
    "                predicted[i,1]=1-p0\n",
    "            pred_BERT=predicted\n",
    "\n",
    "            w=data\n",
    "            w['predicted_HAN_neg']=pred_HAN[:,0]\n",
    "            w['predicted_HAN_pos']=pred_HAN[:,1]\n",
    "            w['predicted_BERT_neg']=pred_BERT[:,0]\n",
    "            w['predicted_BERT_pos']=pred_BERT[:,1]\n",
    "\n",
    "            orig_truth=[]\n",
    "            for e in w['Emotion'].values:\n",
    "                if e=='Negative' or e=='Very negative':\n",
    "                    orig_truth.append(0)\n",
    "                elif e=='Positive' or e=='Very Positive':\n",
    "                    orig_truth.append(1)\n",
    "                elif e=='Neutral':\n",
    "                    orig_truth.append(2)\n",
    "                else:\n",
    "                    orig_truth.append(3)\n",
    "            w['truth_label']=np.array(orig_truth)\n",
    "            w['truth_rand']=rand_truth\n",
    "            w['schoolyear']=s+y\n",
    "            w['school']=s\n",
    "            w['year']=y\n",
    "            df_all = df_all.append(w,ignore_index = True)\n",
    "\n",
    "print(ii)\n",
    "ii+=1\n",
    "#append dartmouth to df\n",
    "s='dartmouth'\n",
    "f=s+'.p'\n",
    "os.chdir(path_result)\n",
    "predicted=pickle.load(open(f,'rb'))\n",
    "m=softmax(predicted,axis=1)\n",
    "pred_HAN=m\n",
    "\n",
    "f=s+'_score.csv'\n",
    "os.chdir(path_data)\n",
    "predicted=pd.read_csv(f,skip_blank_lines=True)\n",
    "predicted=predicted[['emo_pred_neg','emo_pred_pos']].values\n",
    "for i in range(len(predicted)):\n",
    "    p0=predicted[i,0]\n",
    "    #predicted[i,0]=p[0]/(p[0]+p[1])\n",
    "    predicted[i,1]=1-p0\n",
    "pred_BERT=predicted\n",
    "\n",
    "print(1)\n",
    "f4='dartmouth.csv'\n",
    "os.chdir(path_data)\n",
    "data4=pd.read_csv(f4,skip_blank_lines=True)\n",
    "data4['year']='0'\n",
    "for d in range(len(data4['id'])):\n",
    "    data4['year'][d]=str(data4['time'][d])[0:4]\n",
    "data = data4\n",
    "\n",
    "print(2)\n",
    "f=\"label_emt3_\"+s+\".csv\"\n",
    "os.chdir(path_data)\n",
    "rand_truth1=pd.read_csv(f,skip_blank_lines=True, header=None)#.values\n",
    "rand_truth=np.argmax(rand_truth1.values,axis=1)\n",
    "\n",
    "print(3)\n",
    "w=data\n",
    "w['predicted_HAN_neg']=pred_HAN[:,0]\n",
    "w['predicted_HAN_pos']=pred_HAN[:,1]\n",
    "w['predicted_BERT_neg']=pred_BERT[:,0]\n",
    "w['predicted_BERT_pos']=pred_BERT[:,1]\n",
    "\n",
    "print(4)\n",
    "orig_truth=[]\n",
    "for e in w['Emotion'].values:\n",
    "    if e=='Negative' or e=='Very negative':\n",
    "        orig_truth.append(0)\n",
    "    elif e=='Positive' or e=='Very Positive':\n",
    "        orig_truth.append(1)\n",
    "    elif e=='Neutral':\n",
    "        orig_truth.append(2)\n",
    "    else:\n",
    "        orig_truth.append(3)\n",
    "w['truth_label']=np.array(orig_truth)\n",
    "w['truth_rand']=rand_truth\n",
    "w['schoolyear']=s\n",
    "w['school']=s\n",
    "df_all = df_all.append(w,ignore_index = True)\n",
    "\n",
    "#--------------------------------normalize all probability using cut0ff--------------\n",
    "cutoff_han=0.428274\n",
    "cutoff_bert=0.692322\n",
    "\n",
    "\n",
    "df_all['pred_han_neg_norm']=int(0)\n",
    "df_all['pred_han_pos_norm']=int(0)\n",
    "df_all['pred_bert_neg_norm']=int(0)\n",
    "df_all['pred_bert_pos_norm']=int(0)\n",
    "\n",
    "for d in range(len(df_all['body'])):\n",
    "    if df_all.iloc[d]['predicted_HAN_pos']>=cutoff_han:\n",
    "        newpos=0.5*(df_all.iloc[d]['predicted_HAN_pos']-cutoff_han)/(1-cutoff_han)+0.5\n",
    "    elif df_all.iloc[d]['predicted_HAN_pos']<cutoff_han:\n",
    "        newpos=0.5*df_all.iloc[d]['predicted_HAN_pos']/cutoff_han\n",
    "    df_all.iloc[d, df_all.columns.get_loc('pred_han_pos_norm')]=newpos\n",
    "    df_all.iloc[d, df_all.columns.get_loc('pred_han_neg_norm')]=1-newpos\n",
    "    \n",
    "    if df_all.iloc[d]['predicted_BERT_pos']>=cutoff_bert:\n",
    "        newpos=0.5*(df_all.iloc[d]['predicted_BERT_pos']-cutoff_bert)/(1-cutoff_bert)+0.5\n",
    "    elif df_all.iloc[d]['predicted_BERT_pos']<cutoff_bert:\n",
    "        newpos=0.5*df_all.iloc[d]['predicted_BERT_pos']/cutoff_bert\n",
    "    df_all.iloc[d, df_all.columns.get_loc('pred_bert_pos_norm')]=newpos\n",
    "    df_all.iloc[d, df_all.columns.get_loc('pred_bert_neg_norm')]=1-newpos\n",
    "    \n",
    "    \n",
    "    if d%5000==0: print(d)\n",
    "#(df)#.iloc[1])#['predicted_HAN_neg'])\n",
    "print('df_all finished')\n",
    "\n",
    "#---------------------------- using logistic regression to get ensemble prediction----\n",
    "betas=[-2.97772323,2.4231413,3.24225897]\n",
    "\n",
    "df_all['pred_esm']=0\n",
    "df_all['pred_HAN']=0\n",
    "df_all['pred_BERT']=0\n",
    "schoolyears=[\"notredame2019\",\"notredame2020\",\"uofm2019\",\"uofm2020\",\"columbia2019\",\"columbia2020\",\"UCSD2019\",\"UCSD2020\",\"berkeley2019\",\"berkeley2020\",\"Harvard2019\",\"Harvard2020\",\"ucla2019\",\"ucla2020\",\"dartmouth\"]        \n",
    "for d in range(len(df_all['schoolyear'])):\n",
    "    negHAN=df_all['pred_han_neg_norm'].iloc[d]\n",
    "    posHAN=df_all['pred_han_pos_norm'].iloc[d]\n",
    "    negBERT=df_all['pred_bert_neg_norm'].iloc[d]\n",
    "    posBERT=df_all['pred_bert_pos_norm'].iloc[d]\n",
    "    if posHAN>=0.5:\n",
    "        #df['pred_HAN'].iloc[d]=0\n",
    "        df_all.iloc[d, df_all.columns.get_loc('pred_HAN')] =1\n",
    "    elif posHAN<=0.5:\n",
    "        #df['pred_HAN'].iloc[d]=1\n",
    "        df_all.iloc[d, df_all.columns.get_loc('pred_HAN')] =0\n",
    "    if posBERT>=0.5:\n",
    "        #df['pred_BERT'].iloc[d]=0\n",
    "        df_all.iloc[d, df_all.columns.get_loc('pred_BERT')] =1\n",
    "    elif posBERT<=0.5:\n",
    "        #df['pred_BERT'].iloc[d]=1\n",
    "        df_all.iloc[d, df_all.columns.get_loc('pred_BERT')] =0\n",
    "    log_pos_odds=betas[0]+betas[1]*posHAN+betas[2]*posBERT\n",
    "    \n",
    "    df_all.iloc[d, df_all.columns.get_loc('pred_esm')]=int(log_pos_odds>0)\n",
    "\n",
    "\n",
    "\n",
    "#------------transform data to GLMM \n",
    "os.chdir(path_data)\n",
    "schools = [\"notredame\",\"uofm\",\"columbia\",\"dartmouth\",\"UCSD\",\"berkeley\",\"Harvard\",\"ucla\"]\n",
    "categ={\"notredame\":[1,1,1],\"uofm\":[1,1,0],\"columbia\":[1,0,1],\"dartmouth\":[0,1,1],\n",
    "       \"UCSD\":[1,0,0],\"berkeley\":[0,1,0],\"Harvard\":[0,0,1],\"ucla\":[0,0,0]}\n",
    "\n",
    "#Time period: Aug to Nov 2019 (baseline) and  Aug to Nov. 2020;\n",
    "#A in person learning 1; others (online, hybrid) 0\n",
    "#B small city 1, large city 0\n",
    "#C private 1, public 0\n",
    "#   A  B  C \n",
    "#1  1  1  1  \n",
    "#2  1  1  0 \n",
    "#3  1  0  1   \n",
    "#4  0  1  1\n",
    "#5  1  0  0   \n",
    "#6  0  1  0 \n",
    "#7  0  0  1   \n",
    "#8  0  0  0  \n",
    "\n",
    "#1 Notre Dame (in-person learning 1, small city 1, private 1)\n",
    "#2  Michigan   ( in-person learning  1,  small city 1, public 0)\n",
    "#3. Columbia   ( in-person  1, large city 0, private 1) \n",
    "#4. Dartmouth  (online 0,  small city 1, private 1)\n",
    "#5  UCSD (in-person learning 1,  large city 0 , public 0)  \n",
    "#6  xxx   (0 online  small city 1, public 0)  \n",
    "#7  Harvard    (online 0,  large city 0, private 1)\n",
    "#8  UCLA (online 0,  large city 0, public 0)\n",
    "\n",
    "#Positive: 1, negative:0\n",
    "#2020:1, 2019:0\n",
    "for d in range(len(df_all[\"schoolyear\"])):\n",
    "    if (d/1000-int(d/1000))==0:\n",
    "        print(d)\n",
    "    y=df_all['year'][d]\n",
    "    s=df_all['school'][d]\n",
    "    #sentence=data[\"body\"][d]\n",
    "    #emb=np.array(use(sentence))[0]\n",
    "    line=[df_all[\"pred_esm\"][d]]\n",
    "    line.append(int(y=='2020'))\n",
    "    if categ[s][0]==1:\n",
    "        line.append(1)\n",
    "    elif categ[s][0]==0:\n",
    "        if y=='2020':\n",
    "            line.append(0)\n",
    "        elif y=='2019':\n",
    "            line.append(1)\n",
    "    line.append(categ[s][1])\n",
    "    line.append(categ[s][2])\n",
    "    line.append(schools.index(s))\n",
    "    #line=line+emb.tolist()\n",
    "    name='GLMM_esm.csv'\n",
    "    os.chdir(path_result)\n",
    "    e=open(name, 'a',newline='')\n",
    "    with e:\n",
    "        writer = csv.writer(e, delimiter=',')\n",
    "        writer.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "outside-attendance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "147000\n",
      "148000\n",
      "149000\n",
      "150000\n",
      "151000\n",
      "152000\n",
      "153000\n",
      "154000\n",
      "155000\n",
      "156000\n",
      "157000\n",
      "158000\n",
      "159000\n",
      "160000\n",
      "161000\n",
      "162000\n",
      "163000\n",
      "164000\n",
      "165000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "147000\n",
      "148000\n",
      "149000\n",
      "150000\n",
      "151000\n",
      "152000\n",
      "153000\n",
      "154000\n",
      "155000\n",
      "156000\n",
      "157000\n",
      "158000\n",
      "159000\n",
      "160000\n",
      "161000\n",
      "162000\n",
      "163000\n",
      "164000\n",
      "165000\n"
     ]
    }
   ],
   "source": [
    "#get GLMM ready for BERT alone and RoBERTa alone\n",
    "path_result='C:\\\\Backup of covid project\\\\2cls_CScombined_negVSnonneg\\\\results_Cmodel\\\\'\n",
    "path_data=\"C:\\\\Backup of covid project\\\\2cls_CScombined_negVSnonneg\\\\data\\\\\"\n",
    "path_code=\"C:\\\\Backup of covid project\\\\2cls_CScombined_negVSnonneg\\\\\"\n",
    "\n",
    "os.chdir(path_data)\n",
    "\n",
    "types=[\"comment\"]\n",
    "years=['2019','2020']\n",
    "#years=['2020']\n",
    "schools = [\"notredame\",\"uofm\",\"columbia\",\"dartmouth\",\"UCSD\",\"berkeley\",\"Harvard\",\"ucla\"]\n",
    "categ={\"notredame\":[1,1,1],\"uofm\":[1,1,0],\"columbia\":[1,0,1],\"dartmouth\":[0,1,1],\n",
    "       \"UCSD\":[1,0,0],\"berkeley\":[0,1,0],\"Harvard\":[0,0,1],\"ucla\":[0,0,0]}\n",
    "\n",
    "#Time period: Aug to Nov 2019 (baseline) and  Aug to Nov. 2020;\n",
    "#A in person learning 1; others (online, hybrid) 0\n",
    "#B small city 1, large city 0\n",
    "#C private 1, public 0\n",
    "#   A  B  C \n",
    "#1  1  1  1  \n",
    "#2  1  1  0 \n",
    "#3  1  0  1   \n",
    "#4  0  1  1\n",
    "#5  1  0  0   \n",
    "#6  0  1  0 \n",
    "#7  0  0  1   \n",
    "#8  0  0  0  \n",
    "\n",
    "#1 Notre Dame (in-person learning 1, small city 1, private 1)\n",
    "#2  Michigan   ( in-person learning  1,  small city 1, public 0)\n",
    "#3. Columbia   ( in-person  1, large city 0, private 1) \n",
    "#4. Dartmouth  (online 0,  small city 1, private 1)\n",
    "#5  UCSD (in-person learning 1,  large city 0 , public 0)  \n",
    "#6  UCB   (0 online  small city 1, public 0)  \n",
    "#7  Harvard    (online 0,  large city 0, private 1)\n",
    "#8  UCLA (online 0,  large city 0, public 0)\n",
    "\n",
    "#Positive: 1, negative:0\n",
    "#2020:1, 2019:0\n",
    "att_com=['time','id','body','Emotion','Topic','emo_pred']\n",
    "emo=[\"Very Positive\",\"Positive\",\"Neutral\",\"Negative\",\"Very negative\"]\n",
    "top=[\"Covid\",\"Academics\",\"Sports\",\"Campus/Students Life\",\"Social Media\",\"Religion\",\"Politics\",\"Others\"]\n",
    "\n",
    "#Positive: 1, negative:0\n",
    "for d in range(len(df_all[\"schoolyear\"])):\n",
    "    if (d/1000-int(d/1000))==0:\n",
    "        print(d)\n",
    "    y=df_all['year'][d]\n",
    "    s=df_all['school'][d]\n",
    "    #sentence=data[\"body\"][d]\n",
    "    #emb=np.array(use(sentence))[0]\n",
    "    line=[df_all[\"pred_HAN\"][d]]\n",
    "    line.append(int(y=='2020'))\n",
    "    if categ[s][0]==1:\n",
    "        line.append(1)\n",
    "    elif categ[s][0]==0:\n",
    "        if y=='2020':\n",
    "            line.append(0)\n",
    "        elif y=='2019':\n",
    "            line.append(1)\n",
    "    line.append(categ[s][1])\n",
    "    line.append(categ[s][2])\n",
    "    line.append(schools.index(s))\n",
    "    #line=line+emb.tolist()\n",
    "    name='GLMM_esm_han.csv'\n",
    "    os.chdir(path_result)\n",
    "    e=open(name, 'a',newline='')\n",
    "    with e:\n",
    "        writer = csv.writer(e, delimiter=',')\n",
    "        writer.writerow(line)\n",
    "\n",
    "        \n",
    "for d in range(len(df_all[\"schoolyear\"])):\n",
    "    if (d/1000-int(d/1000))==0:\n",
    "        print(d)\n",
    "    y=df_all['year'][d]\n",
    "    s=df_all['school'][d]\n",
    "    #sentence=data[\"body\"][d]\n",
    "    #emb=np.array(use(sentence))[0]\n",
    "    line=[df_all[\"pred_BERT\"][d]]\n",
    "    line.append(int(y=='2020'))\n",
    "    if categ[s][0]==1:\n",
    "        line.append(1)\n",
    "    elif categ[s][0]==0:\n",
    "        if y=='2020':\n",
    "            line.append(0)\n",
    "        elif y=='2019':\n",
    "            line.append(1)\n",
    "    line.append(categ[s][1])\n",
    "    line.append(categ[s][2])\n",
    "    line.append(schools.index(s))\n",
    "    #line=line+emb.tolist()\n",
    "    name='GLMM_esm_bert.csv'\n",
    "    os.chdir(path_result)\n",
    "    e=open(name, 'a',newline='')\n",
    "    with e:\n",
    "        writer = csv.writer(e, delimiter=',')\n",
    "        writer.writerow(line)\n",
    "#df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "undefined-gossip",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{2}{5em}{UCLA} & 2019 & 6121 & 10773 & 16894 & 36.23\\\\\n",
      " & 2020 & 7680 & 11034 & 18714 & 41.04\\\\\n",
      "\\hline\n",
      "\\multirow{2}{5em}{UCSD} & 2019 & 6502 & 11000 & 17502 & 37.15\\\\\n",
      " & 2020 & 6696 & 10650 & 17346 & 38.60\\\\\n",
      "\\hline\n",
      "\\multirow{2}{5em}{UCB} & 2019 & 6650 & 10023 & 16673 & 39.88\\\\\n",
      " & 2020 & 7699 & 10495 & 18194 & 42.32\\\\\n",
      "\\hline\n",
      "\\multirow{2}{5em}{UMich} & 2019 & 4126 & 8398 & 12524 & 32.94\\\\\n",
      " & 2020 & 6922 & 7957 & 14879 & 46.52\\\\\n",
      "\\hline\n",
      "\\multirow{2}{5em}{Harvard} & 2019 & 935 & 1958 & 2893 & 32.32\\\\\n",
      " & 2020 & 1138 & 2416 & 3554 & 32.02\\\\\n",
      "\\hline\n",
      "\\multirow{2}{5em}{Columbia} & 2019 & 1686 & 3345 & 5031 & 33.51\\\\\n",
      " & 2020 & 3423 & 5914 & 9337 & 36.66\\\\\n",
      "\\hline\n",
      "\\multirow{2}{5em}{Dartmouth} & 2019 & 308 & 966 & 1274 & 24.18\\\\\n",
      " & 2020 & 284 & 942 & 1226 & 23.16\\\\\n",
      "\\hline\n",
      "\\multirow{2}{5em}{ND} & 2019 & 395 & 1184 & 1579 & 25.02\\\\\n",
      " & 2020 & 4232 & 3718 & 7950 & 53.23\\\\\n",
      "\\hline\n",
      "\\multirow{2}{5em}{total} & 2019 & 26723 & 47647 & 74370 & 35.93\\\\\n",
      " & 2020 & 38074 & 53126 & 91200 & 41.75\\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "#format first block for table4 in plosone paper\n",
    "\n",
    "years=['2019','2020']\n",
    "methods=['GAT','bert','ens']\n",
    "schoolyears2019=[\"ucla2019\",\"UCSD2019\",\"berkeley2019\",\"uofm2019\",\"Harvard2019\",\"columbia2019\",\"dartmouth2019\",\"notredame2019\",'overall2019']\n",
    "schoolyears2020=[\"ucla2020\",\"UCSD2020\",\"berkeley2020\",\"uofm2020\",\"Harvard2020\",\"columbia2020\",\"dartmouth2020\",\"notredame2020\",'overall2020']\n",
    "schools=[\"ucla\",\"UCSD\",\"berkeley\",\"uofm\",\"Harvard\",\"columbia\",\"dartmouth\",\"notredame\"]\n",
    "schoolnames=[\"UCLA\",\"UCSD\",\"UCB\",\"UMich\",\"Harvard\",\"Columbia\",\"Dartmouth\",\"ND\"]\n",
    "neg2019=[]\n",
    "pos2019=[]\n",
    "total2019=[]\n",
    "\n",
    "neg2020=[]\n",
    "pos2020=[]\n",
    "total2020=[]\n",
    "for s in schools:\n",
    "    for y in years:\n",
    "        if y=='2019':\n",
    "            line='\\\\multirow{2}{5em}{'+schoolnames[schools.index(s)]+'}'+' & 2019 & '\n",
    "            neg=len(df_all.loc[(df_all.pred_esm==float(0)) & (df_all.school==s) & (df_all.year==(y))]['year'])\n",
    "            pos=len(df_all.loc[(df_all.pred_esm==float(1)) & (df_all.school==s) & (df_all.year==(y))]['year'])\n",
    "            total=neg+pos\n",
    "            neg2019.append(neg)\n",
    "            pos2019.append(pos)\n",
    "            total2019.append(total)\n",
    "        elif y=='2020':\n",
    "            line=' & 2020 & '\n",
    "            neg=len(df_all.loc[(df_all.pred_esm==float(0)) & (df_all.school==s) & (df_all.year==(y))]['year'])\n",
    "            pos=len(df_all.loc[(df_all.pred_esm==float(1)) & (df_all.school==s) & (df_all.year==(y))]['year'])\n",
    "            total=neg+pos\n",
    "            neg2020.append(neg)\n",
    "            pos2020.append(pos)\n",
    "            total2020.append(total)\n",
    "        perc='{:.2f}'.format(round(neg/total*100, 2))\n",
    "        line=line+str(neg)+' & '+str(pos)+' & '+str(total)+' & '+perc+\"\\\\\\\\\"\n",
    "        print(line)\n",
    "    print('\\\\hline')\n",
    "line='\\\\multirow{2}{5em}{total}'+' & 2019 & '\n",
    "neg=sum(neg2019)\n",
    "pos=sum(pos2019)\n",
    "total=sum(total2019)\n",
    "perc='{:.2f}'.format(round(neg/total*100, 2))\n",
    "line=line+str(neg)+' & '+str(pos)+' & '+str(total)+' & '+perc+\"\\\\\\\\\"\n",
    "print(line)\n",
    "\n",
    "line=' & 2020 & '\n",
    "neg=sum(neg2020)\n",
    "pos=sum(pos2020)\n",
    "total=sum(total2020)\n",
    "perc='{:.2f}'.format(round(neg/total*100, 2))\n",
    "line=line+str(neg)+' & '+str(pos)+' & '+str(total)+' & '+perc+\"\\\\\\\\\"\n",
    "print(line)\n",
    "print('\\\\hline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-violence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
